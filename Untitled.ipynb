{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d345d033-85a7-42df-a203-3bd1c896c5cd",
   "metadata": {},
   "source": [
    "Disentangling before Composing\n",
    "==========\n",
    "#### This is a simple notebook for DBC. Such an awesome idea! ####   \n",
    "## 1. Dataset.py\n",
    "\n",
    "import external libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db9a1d8-a1cf-407d-b7dc-2ffc5f711c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# external libs\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "from os.path import join as ospj\n",
    "from glob import glob\n",
    "# torch libs\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "# local libs\n",
    "from utils.utils import chunks\n",
    "from itertools import product\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fc6d24-8f12-4461-80a0-868b91dd5401",
   "metadata": {},
   "source": [
    "Specify the graphics card to be used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ba289e-4493-458f-869e-60995de77d6c",
   "metadata": {},
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5871bb62-61f6-4b09-81fb-7c0f7d25a276",
   "metadata": {},
   "source": [
    "Define the basic Image Loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476a3e31-9255-4765-9487-fdb3ef623bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageLoader:\n",
    "    def __init__(self, root):\n",
    "        self.root_dir = root\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = Image.open(ospj(self.root_dir, img)).convert('RGB')\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675b89c5-e493-4cde-b0e9-e743faee7455",
   "metadata": {},
   "source": [
    "It receive a root dir and a **img dir**. Convert and return the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb3daec-28b0-4f12-81ed-9c3b87e71dbd",
   "metadata": {},
   "source": [
    "Now we need to preprocess the raw imgs："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8ff8aa-2abb-444e-81b4-aac2fbd4525f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_transform(phase):\n",
    "    mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "\n",
    "    if phase == 'train':\n",
    "        transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "\n",
    "    elif phase == 'val' or phase == 'test':\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c1e711-f53e-4f79-91a9-ae52226a6fb9",
   "metadata": {},
   "source": [
    "Simple tranform decided by phase.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a527d8-cf19-4980-8d20-fb03e120c16e",
   "metadata": {},
   "source": [
    "Then we need **DataSet Class**:\n",
    "I show the complete code first   \n",
    "Never mind it    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a7a2d6-4dee-4a46-a24a-755ace2d8f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompositionDataset(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            root,\n",
    "            phase,\n",
    "            split='compositional-split'\n",
    "    ):\n",
    "        self.root = root\n",
    "        self.phase = phase\n",
    "        self.split = split\n",
    "        self.feat_dim = 512\n",
    "\n",
    "        self.attrs, self.objs, self.pairs, self.train_pairs, self.val_pairs, self.test_pairs = self.parse_split()\n",
    "        self.train_data, self.val_data, self.test_data = self.get_split_info()\n",
    "\n",
    "        self.obj2idx = {obj: idx for idx, obj in enumerate(self.objs)}\n",
    "        self.attr2idx = {attr: idx for idx, attr in enumerate(self.attrs)}\n",
    "\n",
    "        if self.phase == 'train':\n",
    "            self.pair2idx = {pair: idx for idx, pair in enumerate(self.train_pairs)}\n",
    "        else:\n",
    "            self.pair2idx = {pair: idx for idx, pair in enumerate(self.pairs)}\n",
    "        self.all_pair2idx = {pair: idx for idx, pair in enumerate(self.pairs)}\n",
    "\n",
    "        if self.phase == 'train':\n",
    "            self.data = self.train_data\n",
    "        elif self.phase == 'val':\n",
    "            self.data = self.val_data\n",
    "        elif self.phase == 'test':\n",
    "            self.data = self.test_data\n",
    "\n",
    "        self.all_data = self.train_data + self.val_data + self.test_data\n",
    "\n",
    "        print('Dataset loaded')\n",
    "        print('Train pairs: {}, Validation pairs: {}, Test Pairs: {}'.format(\n",
    "            len(self.train_pairs), len(self.val_pairs), len(self.test_pairs)))\n",
    "        print('Train images: {}, Validation images: {}, Test images: {}'.format(\n",
    "            len(self.train_data), len(self.val_data), len(self.test_data)))\n",
    "\n",
    "        self.sample_indices = list(range(len(self.data)))\n",
    "\n",
    "        self.transform = dataset_transform(self.phase)\n",
    "        self.loader = ImageLoader(ospj(self.root, 'images'))\n",
    "\n",
    "    def parse_split(self):\n",
    "        def parse_pairs(pair_list):\n",
    "            with open(pair_list, 'r') as f:\n",
    "                pairs = f.read().strip().split('\\n')\n",
    "                pairs = [line.split() for line in pairs]\n",
    "                pairs = list(map(tuple, pairs))\n",
    "\n",
    "            attrs, objs = zip(*pairs)\n",
    "            return attrs, objs, pairs\n",
    "\n",
    "        tr_attrs, tr_objs, tr_pairs = parse_pairs(ospj(self.root, self.split, 'train_pairs.txt').replace('\\\\', '/'))\n",
    "        vl_attrs, vl_objs, vl_pairs = parse_pairs(ospj(self.root, self.split, 'val_pairs.txt').replace('\\\\', '/'))\n",
    "        ts_attrs, ts_objs, ts_pairs = parse_pairs(ospj(self.root, self.split, 'test_pairs.txt').replace('\\\\', '/'))\n",
    "\n",
    "        all_attrs, all_objs = sorted(\n",
    "            list(set(tr_attrs + vl_attrs + ts_attrs))), sorted(\n",
    "            list(set(tr_objs + vl_objs + ts_objs)))\n",
    "        all_pairs = sorted(list(set(tr_pairs + vl_pairs + ts_pairs)))\n",
    "        return all_attrs, all_objs, all_pairs, tr_pairs, vl_pairs, ts_pairs\n",
    "\n",
    "    def get_split_info(self):\n",
    "        data = torch.load(ospj(self.root, 'metadata_{}.t7'.format(self.split)))\n",
    "        train_data, val_data, test_data = [], [], []\n",
    "\n",
    "        for instance in data:\n",
    "            image, attr, obj, settype = instance['image'], instance['attr'], \\\n",
    "                instance['obj'], instance['set']\n",
    "            curr_data = [image, attr, obj]\n",
    "            if attr == 'NA' or (attr, obj) not in self.pairs or settype == 'NA':\n",
    "                continue\n",
    "            if settype == 'train':\n",
    "                train_data.append(curr_data)\n",
    "            elif settype == 'val':\n",
    "                val_data.append(curr_data)\n",
    "            else:\n",
    "                test_data.append(curr_data)\n",
    "\n",
    "        return train_data, val_data, test_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index = self.sample_indices[index]\n",
    "        image, attr, obj = self.data[index]\n",
    "\n",
    "        if self.phase == 'train':\n",
    "            positive_attr = self.same_A_diff_B(label_A=attr, label_B=obj, phase='attr')\n",
    "            same_attr_image = positive_attr[0]\n",
    "            one_obj = positive_attr[2]\n",
    "            one_attr = positive_attr[1]\n",
    "            positive_obj = self.same_A_diff_B(label_A=obj, label_B=attr, phase='obj')\n",
    "            same_obj_image = positive_obj[0]\n",
    "            two_attr = positive_obj[1]\n",
    "            two_obj = positive_obj[2]\n",
    "\n",
    "        img = self.loader(image)\n",
    "        img = self.transform(img)\n",
    "        if self.phase == 'train':\n",
    "            same_attr_img = self.loader(same_attr_image)\n",
    "            same_attr_img = self.transform(same_attr_img)\n",
    "            same_obj_img = self.loader(same_obj_image)\n",
    "            same_obj_img = self.transform(same_obj_img)\n",
    "\n",
    "        data = [img, self.attr2idx[attr], self.obj2idx[obj], self.pair2idx[(attr, obj)]]\n",
    "\n",
    "        if self.phase == 'train':\n",
    "            data += [same_attr_img, self.obj2idx[one_obj], same_obj_img, self.attr2idx[two_attr],\n",
    "                     self.attr2idx[one_attr], self.obj2idx[two_obj],\n",
    "                     self.pair2idx[(attr, one_obj)], self.pair2idx[(two_attr, obj)]]\n",
    "\n",
    "        return data\n",
    "\n",
    "    def same_A_diff_B(self, label_A, label_B, phase='attr'):\n",
    "        data1 = []\n",
    "        for i in range(len(self.train_data)):\n",
    "            if phase == 'attr':\n",
    "                if (self.train_data[i][1] == label_A):\n",
    "                    data1.append(self.train_data[i])\n",
    "            else:\n",
    "                if (self.train_data[i][2] == label_A):\n",
    "                    data1.append(self.train_data[i])\n",
    "\n",
    "        data2 = choice(data1)\n",
    "        return data2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2edec4f-8157-4bd6-81ee-51135ca245bd",
   "metadata": {},
   "source": [
    "I will explain it line by line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4e57fd-6123-4e90-b98b-8ba68dbd6388",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompositionDataset(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            root,\n",
    "            phase,\n",
    "            split='compositional-split'\n",
    "    ):\n",
    "        self.root = root\n",
    "        self.phase = phase\n",
    "        self.split = split\n",
    "        self.feat_dim = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c12141b-9778-4b92-9612-457d02618903",
   "metadata": {},
   "source": [
    "**root, phase, split, feature dim** got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a40969-84e6-4702-8633-d85184c66022",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.attrs, self.objs, self.pairs, self.train_pairs, self.val_pairs, self.test_pairs = self.parse_split()\n",
    "        self.train_data, self.val_data, self.test_data = self.get_split_info()\n",
    "\n",
    "        self.obj2idx = {obj: idx for idx, obj in enumerate(self.objs)}\n",
    "        self.attr2idx = {attr: idx for idx, attr in enumerate(self.attrs)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998cf701-9503-4f2e-add6-ac5f8ab7b669",
   "metadata": {},
   "source": [
    "**attrs, objs, pairs, train_pairs, val_pairs, test_pairs** got from function **parser_split**   \n",
    "Now lets see the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d814f28-62bb-4e6c-a117-db087fb203d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def parse_split(self):\n",
    "        def parse_pairs(pair_list):\n",
    "            with open(pair_list, 'r') as f:\n",
    "                pairs = f.read().strip().split('\\n')\n",
    "                pairs = [line.split() for line in pairs]\n",
    "                pairs = list(map(tuple, pairs))\n",
    "\n",
    "            attrs, objs = zip(*pairs)\n",
    "            return attrs, objs, pairs\n",
    "\n",
    "        tr_attrs, tr_objs, tr_pairs = parse_pairs(ospj(self.root, self.split, 'train_pairs.txt').replace('\\\\', '/'))\n",
    "        vl_attrs, vl_objs, vl_pairs = parse_pairs(ospj(self.root, self.split, 'val_pairs.txt').replace('\\\\', '/'))\n",
    "        ts_attrs, ts_objs, ts_pairs = parse_pairs(ospj(self.root, self.split, 'test_pairs.txt').replace('\\\\', '/'))\n",
    "\n",
    "        all_attrs, all_objs = sorted(\n",
    "            list(set(tr_attrs + vl_attrs + ts_attrs))), sorted(\n",
    "            list(set(tr_objs + vl_objs + ts_objs)))\n",
    "        all_pairs = sorted(list(set(tr_pairs + vl_pairs + ts_pairs)))\n",
    "        return all_attrs, all_objs, all_pairs, tr_pairs, vl_pairs, ts_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2178b76-5ec6-47b1-a134-a694fa8cefba",
   "metadata": {},
   "source": [
    "The function in split **parse_pairs** is the core part.   \n",
    "It need parameters **root and split**    \n",
    "Its parameter **pair list** is a filename(split txt) with its dir.   \n",
    "For example file is \"WC1 M1\\n WC2 M2\"    \n",
    "It return 3 turtles (split by space and enter):   \n",
    "**attrs**: (WC1, WC2)    \n",
    "**objs**: (M1, M2)     \n",
    "**pairs**: ((WC1,M1), (WC2,M2))    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8b23ea-18d8-4af7-bba5-0f82cdc0a386",
   "metadata": {},
   "source": [
    "Through different phase we get turples.    \n",
    "**Here I have questions for the sequence of different pairs??**    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708f919c-a16f-4672-95c6-831f70b37f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.train_data, self.val_data, self.test_data = self.get_split_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e30b6a2-1ff5-47f9-9d64-7fb0f5e2c2a6",
   "metadata": {},
   "source": [
    "Lets see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d099d43c-17c8-4f5c-b7e3-c978acdd9ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_split_info(self):\n",
    "        data = torch.load(ospj(self.root, 'metadata_{}.t7'.format(self.split)))\n",
    "        train_data, val_data, test_data = [], [], []\n",
    "\n",
    "        for instance in data:\n",
    "            image, attr, obj, settype = instance['image'], instance['attr'], \\\n",
    "                instance['obj'], instance['set']\n",
    "            curr_data = [image, attr, obj]\n",
    "            if attr == 'NA' or (attr, obj) not in self.pairs or settype == 'NA':\n",
    "                continue\n",
    "            if settype == 'train':\n",
    "                train_data.append(curr_data)\n",
    "            elif settype == 'val':\n",
    "                val_data.append(curr_data)\n",
    "            else:\n",
    "                test_data.append(curr_data)\n",
    "\n",
    "        return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e246bf-15eb-4f9d-9582-e6deaefade33",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load(ospj(self.root, 'metadata_{}.t7'.format(self.split)))\n",
    "train_data, val_data, test_data = [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c17051-06f9-4473-bbc3-08f5da77ca3a",
   "metadata": {},
   "source": [
    "load the metadata (t7). It contains many data including **image**(img dir), **attr**, **obj**, **set**(test,train,val)     \n",
    "And init list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c461b8b1-8ef8-4b5c-8777-5e9193a5e632",
   "metadata": {},
   "outputs": [],
   "source": [
    "            curr_data = [image, attr, obj]\n",
    "            if attr == 'NA' or (attr, obj) not in self.pairs or settype == 'NA':\n",
    "                continue\n",
    "            if settype == 'train':\n",
    "                train_data.append(curr_data)\n",
    "            elif settype == 'val':\n",
    "                val_data.append(curr_data)\n",
    "            else:\n",
    "                test_data.append(curr_data)\n",
    "\n",
    "        return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27dcf35-fabc-43b6-8023-7d96c81d2441",
   "metadata": {},
   "source": [
    "That doesnt make sense. We just need to know this function return **three 2-dim list**    \n",
    "**train_data=[[image, attr, obj], [image, attr, obj], [image, attr, obj]]**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d09e908-ba70-43ed-b602-c9cee57eb983",
   "metadata": {},
   "source": [
    "Here we get the following paras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba01ebe-a6e0-41ec-adb9-f49601d33d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.train_data, self.val_data, self.test_data = self.get_split_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c94ed8c-99ec-4d67-b11a-76ad2b989ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.obj2idx = {obj: idx for idx, obj in enumerate(self.objs)}\n",
    "self.attr2idx = {attr: idx for idx, attr in enumerate(self.attrs)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e304b8b-966c-4dd1-922c-32c9fd367dd2",
   "metadata": {},
   "source": [
    "This operation aims to create a dictionary from objs and attrs (2idx).     \n",
    "for example, `self.objs` is all_objs returned by parse_split    \n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866c4a12-183a-4383-ae2d-900b0a316280",
   "metadata": {},
   "source": [
    "enumerate() is a iteration to make a combination     \n",
    "`obj:idx` means objs is key while idx is value.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61efe8b-41f8-4868-9f09-190ee6e93630",
   "metadata": {},
   "source": [
    "```       \r\n",
    "self.obj2idx = {'apple': 0, 'car': 1, 'dog': 2示\r\n",
    "`     ``\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfff2e9-8806-47c6-ba3b-46ce6e217e8b",
   "metadata": {},
   "source": [
    "Here we know that objs2idx is actually a dict to transfer name to idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016e4dd2-7589-40ca-9886-17d976cf7e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "        if self.phase == 'train':\n",
    "            self.pair2idx = {pair: idx for idx, pair in enumerate(self.train_pairs)}\n",
    "        else:\n",
    "            self.pair2idx = {pair: idx for idx, pair in enumerate(self.pairs)}\n",
    "        self.all_pair2idx = {pair: idx for idx, pair in enumerate(self.pairs)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7065e820-774a-4ed7-805d-0d6e35169d3d",
   "metadata": {},
   "source": [
    "pairs is all_pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10977baa-4ab8-435c-9926-9e339044a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "{('apple', 'red'): 0, ('car', 'shiny'): 1, ('dog', 'furry'): 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1849827d-c0c2-4803-907b-e49bc17b2c05",
   "metadata": {},
   "source": [
    "Following code is EZ, 2-dim list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d8c572-598b-41ae-bf9b-65951a395594",
   "metadata": {},
   "outputs": [],
   "source": [
    "if self.phase == 'train':\n",
    "            self.data = self.train_data\n",
    "        elif self.phase == 'val':\n",
    "            self.data = self.val_data\n",
    "        elif self.phase == 'test':\n",
    "            self.data = self.test_data\n",
    "\n",
    "        self.all_data = self.train_data + self.val_data + self.test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee54e65-88fd-4e19-8083-95d65c370347",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.sample_indices = list(range(len(self.data)))\n",
    "self.transform = dataset_transform(self.phase)\n",
    "self.loader = ImageLoader(ospj(self.root, 'images'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfcd320-ed16-4278-b9e8-a0de6872f7ab",
   "metadata": {},
   "source": [
    "Get a idx list like [0,1,2,3...N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738e2ca2-061e-4467-abef-b49b4e9f4b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def same_A_diff_B(self, label_A, label_B, phase='attr'):\n",
    "        data1 = []\n",
    "        for i in range(len(self.train_data)):\n",
    "            if phase == 'attr':\n",
    "                if (self.train_data[i][1] == label_A):\n",
    "                    data1.append(self.train_data[i])\n",
    "            else:\n",
    "                if (self.train_data[i][2] == label_A):\n",
    "                    data1.append(self.train_data[i])\n",
    "\n",
    "        data2 = choice(data1)\n",
    "        return data2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3a3ae3-531e-44f9-91f5-0f3ab307efb2",
   "metadata": {},
   "source": [
    "randomly choose a data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d442821c-fda1-4234-a197-706ccf775e92",
   "metadata": {},
   "source": [
    "### Too Complex！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790d5592-76b4-435a-b019-d2c9d229498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata\n",
    "[\n",
    "    [\"img1.jpg\", \"红色\", \"苹果\"],\n",
    "    [\"img2.jpg\", \"条纹\", \"苹果\"],\n",
    "    [\"img3.jpg\", \"金属\", \"汽车\"],\n",
    "    [\"img4.jpg\", \"红色\", \"球\"],\n",
    "    [\"img5.jpg\", \"条纹\", \"汽车\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fde99e9-f598-4a99-a030-a37aa4921227",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "image, attr, obj = \"img1.jpg\", \"红色\", \"苹果\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9adead-aaff-4847-b3b2-4253aeee9b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_attr = self.same_A_diff_B(\"红色\", \"苹果\", \"attr\")\n",
    "# 可能返回 [\"img4.jpg\", \"红色\", \"球\"] （同\"红色\"，不同\"苹果\"）\n",
    "same_attr_image, one_attr, one_obj = \"img4.jpg\", \"红色\", \"球\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068f3bb6-71b9-41b2-a85c-2baa60dce14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tensor(shape=[3,224,224])          # img1.jpg\n",
    "same_attr_img = tensor(shape=[3,224,224]) # img4.jpg\n",
    "same_obj_img = tensor(shape=[3,224,224])  # img2.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f30070-c9d3-4eda-9c64-5f8687c494c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基础数据\n",
    "data = [\n",
    "    img,                     # 原始图像张量\n",
    "    self.attr2idx[\"红色\"],    # 属性ID (假设=0)\n",
    "    self.obj2idx[\"苹果\"],     # 对象ID (假设=0)\n",
    "    self.pair2idx[(\"红色\",\"苹果\")] # 组合ID (假设=0)\n",
    "]\n",
    "\n",
    "# 训练时附加数据\n",
    "data += [\n",
    "    same_attr_img,                      # 同属性图像张量\n",
    "    self.obj2idx[\"球\"],                 # 对比对象ID (假设=2)\n",
    "    same_obj_img,                       # 同对象图像张量\n",
    "    self.attr2idx[\"条纹\"],              # 对比属性ID (假设=1)\n",
    "    self.attr2idx[\"红色\"],              # 原属性ID (仍然是0)\n",
    "    self.obj2idx[\"苹果\"],               # 原对象ID (仍然是0)\n",
    "    self.pair2idx[(\"红色\",\"球\")],       # 新组合ID (假设=3)\n",
    "    self.pair2idx[(\"条纹\",\"苹果\")]      # 新组合ID (假设=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfc4e3f-df05-4ebf-b72a-3d04f4add279",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    tensor([...]),  # img1.jpg的张量\n",
    "    0,              # \"红色\"的ID\n",
    "    0,              # \"苹果\"的ID\n",
    "    0,              # (\"红色\",\"苹果\")的ID\n",
    "    \n",
    "    tensor([...]),  # img4.jpg的张量\n",
    "    2,              # \"球\"的ID\n",
    "    tensor([...]),  # img2.jpg的张量\n",
    "    1,              # \"条纹\"的ID\n",
    "    0,              # \"红色\"的ID (重复)\n",
    "    0,              # \"苹果\"的ID (重复)\n",
    "    3,              # (\"红色\",\"球\")的ID\n",
    "    1               # (\"条纹\",\"苹果\")的ID\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334ed201-f06f-4aec-8283-6592d6fa3f04",
   "metadata": {},
   "source": [
    "Test phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c387576-126e-4f9f-b994-9542d3fe4314",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    tensor([...]),  # 图像张量\n",
    "    0,              # 属性ID\n",
    "    0,              # 对象ID\n",
    "    0               # 组合ID\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f58d0a-0498-4fc8-85eb-eb84f0776fae",
   "metadata": {},
   "source": [
    "## 2. Backbones.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4485f0e7-781c-4756-a0e2-445858e62a48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
