{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d345d033-85a7-42df-a203-3bd1c896c5cd",
   "metadata": {},
   "source": [
    "Disentangling before Composing\n",
    "==========\n",
    "#### This is a simple notebook for DBC. Such an awesome idea! ####   \n",
    "## Dataset.py ##\n",
    "\n",
    "import external libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db9a1d8-a1cf-407d-b7dc-2ffc5f711c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# external libs\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "from os.path import join as ospj\n",
    "from glob import glob\n",
    "# torch libs\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "# local libs\n",
    "from utils.utils import chunks\n",
    "from itertools import product\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fc6d24-8f12-4461-80a0-868b91dd5401",
   "metadata": {},
   "source": [
    "Specify the graphics card to be used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ba289e-4493-458f-869e-60995de77d6c",
   "metadata": {},
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5871bb62-61f6-4b09-81fb-7c0f7d25a276",
   "metadata": {},
   "source": [
    "Define the basic Image Loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476a3e31-9255-4765-9487-fdb3ef623bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageLoader:\n",
    "    def __init__(self, root):\n",
    "        self.root_dir = root\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = Image.open(ospj(self.root_dir, img)).convert('RGB')\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675b89c5-e493-4cde-b0e9-e743faee7455",
   "metadata": {},
   "source": [
    "It receive a root dir and a **img dir**. Convert and return the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb3daec-28b0-4f12-81ed-9c3b87e71dbd",
   "metadata": {},
   "source": [
    "Now we need to preprocess the raw imgsï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8ff8aa-2abb-444e-81b4-aac2fbd4525f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_transform(phase):\n",
    "    mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "\n",
    "    if phase == 'train':\n",
    "        transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "\n",
    "    elif phase == 'val' or phase == 'test':\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c1e711-f53e-4f79-91a9-ae52226a6fb9",
   "metadata": {},
   "source": [
    "Simple tranform decided by phase.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a527d8-cf19-4980-8d20-fb03e120c16e",
   "metadata": {},
   "source": [
    "Then we need **DataSet Class**:\n",
    "I show the complete code first   \n",
    "Never mind it    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a7a2d6-4dee-4a46-a24a-755ace2d8f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompositionDataset(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            root,\n",
    "            phase,\n",
    "            split='compositional-split'\n",
    "    ):\n",
    "        self.root = root\n",
    "        self.phase = phase\n",
    "        self.split = split\n",
    "        self.feat_dim = 512\n",
    "\n",
    "        self.attrs, self.objs, self.pairs, self.train_pairs, self.val_pairs, self.test_pairs = self.parse_split()\n",
    "        self.train_data, self.val_data, self.test_data = self.get_split_info()\n",
    "\n",
    "        self.obj2idx = {obj: idx for idx, obj in enumerate(self.objs)}\n",
    "        self.attr2idx = {attr: idx for idx, attr in enumerate(self.attrs)}\n",
    "\n",
    "        if self.phase == 'train':\n",
    "            self.pair2idx = {pair: idx for idx, pair in enumerate(self.train_pairs)}\n",
    "        else:\n",
    "            self.pair2idx = {pair: idx for idx, pair in enumerate(self.pairs)}\n",
    "        self.all_pair2idx = {pair: idx for idx, pair in enumerate(self.pairs)}\n",
    "\n",
    "        if self.phase == 'train':\n",
    "            self.data = self.train_data\n",
    "        elif self.phase == 'val':\n",
    "            self.data = self.val_data\n",
    "        elif self.phase == 'test':\n",
    "            self.data = self.test_data\n",
    "\n",
    "        self.all_data = self.train_data + self.val_data + self.test_data\n",
    "\n",
    "        print('Dataset loaded')\n",
    "        print('Train pairs: {}, Validation pairs: {}, Test Pairs: {}'.format(\n",
    "            len(self.train_pairs), len(self.val_pairs), len(self.test_pairs)))\n",
    "        print('Train images: {}, Validation images: {}, Test images: {}'.format(\n",
    "            len(self.train_data), len(self.val_data), len(self.test_data)))\n",
    "\n",
    "        self.sample_indices = list(range(len(self.data)))\n",
    "\n",
    "        self.transform = dataset_transform(self.phase)\n",
    "        self.loader = ImageLoader(ospj(self.root, 'images'))\n",
    "\n",
    "    def parse_split(self):\n",
    "        def parse_pairs(pair_list):\n",
    "            with open(pair_list, 'r') as f:\n",
    "                pairs = f.read().strip().split('\\n')\n",
    "                pairs = [line.split() for line in pairs]\n",
    "                pairs = list(map(tuple, pairs))\n",
    "\n",
    "            attrs, objs = zip(*pairs)\n",
    "            return attrs, objs, pairs\n",
    "\n",
    "        tr_attrs, tr_objs, tr_pairs = parse_pairs(ospj(self.root, self.split, 'train_pairs.txt').replace('\\\\', '/'))\n",
    "        vl_attrs, vl_objs, vl_pairs = parse_pairs(ospj(self.root, self.split, 'val_pairs.txt').replace('\\\\', '/'))\n",
    "        ts_attrs, ts_objs, ts_pairs = parse_pairs(ospj(self.root, self.split, 'test_pairs.txt').replace('\\\\', '/'))\n",
    "\n",
    "        all_attrs, all_objs = sorted(\n",
    "            list(set(tr_attrs + vl_attrs + ts_attrs))), sorted(\n",
    "            list(set(tr_objs + vl_objs + ts_objs)))\n",
    "        all_pairs = sorted(list(set(tr_pairs + vl_pairs + ts_pairs)))\n",
    "        return all_attrs, all_objs, all_pairs, tr_pairs, vl_pairs, ts_pairs\n",
    "\n",
    "    def get_split_info(self):\n",
    "        data = torch.load(ospj(self.root, 'metadata_{}.t7'.format(self.split)))\n",
    "        train_data, val_data, test_data = [], [], []\n",
    "\n",
    "        for instance in data:\n",
    "            image, attr, obj, settype = instance['image'], instance['attr'], \\\n",
    "                instance['obj'], instance['set']\n",
    "            curr_data = [image, attr, obj]\n",
    "            if attr == 'NA' or (attr, obj) not in self.pairs or settype == 'NA':\n",
    "                continue\n",
    "            if settype == 'train':\n",
    "                train_data.append(curr_data)\n",
    "            elif settype == 'val':\n",
    "                val_data.append(curr_data)\n",
    "            else:\n",
    "                test_data.append(curr_data)\n",
    "\n",
    "        return train_data, val_data, test_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index = self.sample_indices[index]\n",
    "        image, attr, obj = self.data[index]\n",
    "\n",
    "        if self.phase == 'train':\n",
    "            positive_attr = self.same_A_diff_B(label_A=attr, label_B=obj, phase='attr')\n",
    "            same_attr_image = positive_attr[0]\n",
    "            one_obj = positive_attr[2]\n",
    "            one_attr = positive_attr[1]\n",
    "            positive_obj = self.same_A_diff_B(label_A=obj, label_B=attr, phase='obj')\n",
    "            same_obj_image = positive_obj[0]\n",
    "            two_attr = positive_obj[1]\n",
    "            two_obj = positive_obj[2]\n",
    "\n",
    "        img = self.loader(image)\n",
    "        img = self.transform(img)\n",
    "        if self.phase == 'train':\n",
    "            same_attr_img = self.loader(same_attr_image)\n",
    "            same_attr_img = self.transform(same_attr_img)\n",
    "            same_obj_img = self.loader(same_obj_image)\n",
    "            same_obj_img = self.transform(same_obj_img)\n",
    "\n",
    "        data = [img, self.attr2idx[attr], self.obj2idx[obj], self.pair2idx[(attr, obj)]]\n",
    "\n",
    "        if self.phase == 'train':\n",
    "            data += [same_attr_img, self.obj2idx[one_obj], same_obj_img, self.attr2idx[two_attr],\n",
    "                     self.attr2idx[one_attr], self.obj2idx[two_obj],\n",
    "                     self.pair2idx[(attr, one_obj)], self.pair2idx[(two_attr, obj)]]\n",
    "\n",
    "        return data\n",
    "\n",
    "    def same_A_diff_B(self, label_A, label_B, phase='attr'):\n",
    "        data1 = []\n",
    "        for i in range(len(self.train_data)):\n",
    "            if phase == 'attr':\n",
    "                if (self.train_data[i][1] == label_A):\n",
    "                    data1.append(self.train_data[i])\n",
    "            else:\n",
    "                if (self.train_data[i][2] == label_A):\n",
    "                    data1.append(self.train_data[i])\n",
    "\n",
    "        data2 = choice(data1)\n",
    "        return data2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2edec4f-8157-4bd6-81ee-51135ca245bd",
   "metadata": {},
   "source": [
    "I will explain it line by line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4e57fd-6123-4e90-b98b-8ba68dbd6388",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompositionDataset(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            root,\n",
    "            phase,\n",
    "            split='compositional-split'\n",
    "    ):\n",
    "        self.root = root\n",
    "        self.phase = phase\n",
    "        self.split = split\n",
    "        self.feat_dim = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c12141b-9778-4b92-9612-457d02618903",
   "metadata": {},
   "source": [
    "**root, phase, split, feature dim** got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a40969-84e6-4702-8633-d85184c66022",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.attrs, self.objs, self.pairs, self.train_pairs, self.val_pairs, self.test_pairs = self.parse_split()\n",
    "        self.train_data, self.val_data, self.test_data = self.get_split_info()\n",
    "\n",
    "        self.obj2idx = {obj: idx for idx, obj in enumerate(self.objs)}\n",
    "        self.attr2idx = {attr: idx for idx, attr in enumerate(self.attrs)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998cf701-9503-4f2e-add6-ac5f8ab7b669",
   "metadata": {},
   "source": [
    "**attrs, objs, pairs, train_pairs, val_pairs, test_pairs** got from function **parser_split**   \n",
    "Now lets see the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d814f28-62bb-4e6c-a117-db087fb203d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def parse_split(self):\n",
    "        def parse_pairs(pair_list):\n",
    "            with open(pair_list, 'r') as f:\n",
    "                pairs = f.read().strip().split('\\n')\n",
    "                pairs = [line.split() for line in pairs]\n",
    "                pairs = list(map(tuple, pairs))\n",
    "\n",
    "            attrs, objs = zip(*pairs)\n",
    "            return attrs, objs, pairs\n",
    "\n",
    "        tr_attrs, tr_objs, tr_pairs = parse_pairs(ospj(self.root, self.split, 'train_pairs.txt').replace('\\\\', '/'))\n",
    "        vl_attrs, vl_objs, vl_pairs = parse_pairs(ospj(self.root, self.split, 'val_pairs.txt').replace('\\\\', '/'))\n",
    "        ts_attrs, ts_objs, ts_pairs = parse_pairs(ospj(self.root, self.split, 'test_pairs.txt').replace('\\\\', '/'))\n",
    "\n",
    "        all_attrs, all_objs = sorted(\n",
    "            list(set(tr_attrs + vl_attrs + ts_attrs))), sorted(\n",
    "            list(set(tr_objs + vl_objs + ts_objs)))\n",
    "        all_pairs = sorted(list(set(tr_pairs + vl_pairs + ts_pairs)))\n",
    "        return all_attrs, all_objs, all_pairs, tr_pairs, vl_pairs, ts_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2178b76-5ec6-47b1-a134-a694fa8cefba",
   "metadata": {},
   "source": [
    "The function in split **parse_pairs** is the core part.   \n",
    "It need parameters **root and split**    \n",
    "Its parameter **pair list** is a filename(split txt) with its dir.   \n",
    "For example file is \"WC1 M1\\n WC2 M2\"    \n",
    "It return 3 turtles (split by space and enter):   \n",
    "**attrs**: (WC1, WC2)    \n",
    "**objs**: (M1, M2)     \n",
    "**pairs**: ((WC1,M1), (WC2,M2))    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8b23ea-18d8-4af7-bba5-0f82cdc0a386",
   "metadata": {},
   "source": [
    "Through different phase we get turples.    \n",
    "**Here I have questions for the sequence of different pairs??**    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708f919c-a16f-4672-95c6-831f70b37f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.train_data, self.val_data, self.test_data = self.get_split_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e30b6a2-1ff5-47f9-9d64-7fb0f5e2c2a6",
   "metadata": {},
   "source": [
    "Lets see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d099d43c-17c8-4f5c-b7e3-c978acdd9ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_split_info(self):\n",
    "        data = torch.load(ospj(self.root, 'metadata_{}.t7'.format(self.split)))\n",
    "        train_data, val_data, test_data = [], [], []\n",
    "\n",
    "        for instance in data:\n",
    "            image, attr, obj, settype = instance['image'], instance['attr'], \\\n",
    "                instance['obj'], instance['set']\n",
    "            curr_data = [image, attr, obj]\n",
    "            if attr == 'NA' or (attr, obj) not in self.pairs or settype == 'NA':\n",
    "                continue\n",
    "            if settype == 'train':\n",
    "                train_data.append(curr_data)\n",
    "            elif settype == 'val':\n",
    "                val_data.append(curr_data)\n",
    "            else:\n",
    "                test_data.append(curr_data)\n",
    "\n",
    "        return train_data, val_data, test_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
